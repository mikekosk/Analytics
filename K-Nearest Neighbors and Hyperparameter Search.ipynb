{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to K-Nearest Neighbors and HyperParameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors for Classification\n",
    "\n",
    "Like the K-Means algorithm we covered before this, K-Nearest Neighbors is an example of **lazy learning** in machine learning.  Neither K-means of K-nearest neighbors are generalizable outside of their input data. In order to get usage out of these algorithms, we need to have access to the entire set of training data, even as we try and use our model to make predictions on new data.  This can pose some difficulties when you're dealing with a lot of data...imagine if you have millions of existing data points to test for!\n",
    "\n",
    "We contrast this to eager learning, which is exhibited by all tree based algorithms, support vector machines, or logistic regressions (among many others). Once we have trained an eager model, we can export it as a generalizable function without bringing all of our training data within. \n",
    "\n",
    "That K-Nearest neighbors is a *lazy* model shouldn't be a surprise.  K-NN makes predictions by comparing the new input data to existing points and their labels. Points are predicted based on which points in the training data they are most simialar to.  It is extremely powerful and modifications of it (such as approximate nearest neighbors) power a lot of huge apps like Spotify or Better.\n",
    "\n",
    "In this notebook, we'll be hand coding an implementation of the K-nearest neighbors algorithm as well as comparing it to some other algorithms with regards to classification power on a test set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the KNN Classification Function First"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading the famous Iris dataset to test our KNN's ability to classify flower samples based on their similarity to other flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading Necessary Background Packages\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing Data for classification \n",
    "iris = datasets.load_iris()\n",
    "X = iris.data \n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris dataset has data in 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sampling the data\n",
    "X[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 iris classifications we are predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be splitting the data into Test and Train splits using the super handy built in sklearn function.\n",
    "\n",
    "I've chosen to split the data into 80% train, 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I have printed the length of the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've plotted the first 2 features of the training datasets to get a sense of how well clustered the points are.  Seems that even with 2 features, our data is very well segmented already.  I can see our model doing very well here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1137d57d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBDMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113703810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train[:,1], X_train[:,0], c=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below K-NN classification takes the following arguments:\n",
    "\n",
    "- X_train: Features to build model on\n",
    "- y_train: Labels for training model\n",
    "- X_test: Features to predict on\n",
    "\n",
    "The model outputs the following\n",
    "\n",
    "- y_test: labels for testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The algorithm\n",
    "\n",
    "K nearest neighbors is quite beautiful in its simplicity.\n",
    "\n",
    "1. Given X_Train, X_Test, Y_Train\n",
    "2. Find the *k* nearest points to each x in X_train\n",
    "3. Classify x based on the predominant classification of those *k* nearest points\n",
    "4. Done!\n",
    "\n",
    "Our implementation is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def distance(X, X_train):\n",
    "    return [np.sum((X - x)**2) for x in X_train]\n",
    "    \n",
    "def my_knn_classification(X_train, X_test, y_train, n_neighbors):\n",
    "    #find the closest n_neighbors in X_train to each point in X_test \n",
    "    #assign each point in X_test a label which is the most common label \n",
    "    #of its nearest n_neighbors\n",
    "    #\n",
    "    #return array y_test which is the array of above labels on X_test\n",
    "    y_test = []\n",
    "    for x in X_test:\n",
    "        #find the index of the cloest n_neighbors points to x in X_train\n",
    "        knn = np.argsort(distance(x, X_train))[:n_neighbors]\n",
    "        knn_labels = y_train[knn]\n",
    "        # find the most predominant label of the nearest *k* points\n",
    "        label_counts = Counter(knn_labels)\n",
    "        y_test.append(label_counts.most_common(1)[0][0])\n",
    "    return np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you believe the KNN algorithm is this simple??? Seriously before I understood how it worked I treated it like some magical machine learning black box.  Its that simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test her out! I'm setting my algorithm to look at the 5 nearest points -- Later I'll discuss a more programtic approach to finding the optimal number of *k* neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = my_knn_classification(X_train, X_test, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN correctly classified:  96.6666666667 %\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i] == y_test[i]: num_correct += 1\n",
    "\n",
    "print \"KNN correctly classified: \", num_correct/len(y_hat)*100, \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Almost perfect classification.  Granted, this is a pretty easy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors for Regression\n",
    "\n",
    "For the second half of our implementation, I'll be writing the K-NN algorithm for regression problems.  \n",
    "\n",
    "I'll be loading another great dataset from sklearn containing features and prices of homes in Boston.  We'll be calculating the optimal number of nearest neighbors once we get the base implementation working.\n",
    "\n",
    "K nearest neighbors is quite beautiful in its simplicity, even for regressions.\n",
    "\n",
    "1. Given X_Train, X_Test, Y_Train\n",
    "2. Find the *k* nearest points to each x in X_train\n",
    "3. Predict what Y_test will be for each x based on the average value of Y_train is in its *k* nearest points\n",
    "4. Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import our home price data\n",
    "boston = datasets.load_boston()\n",
    "X = boston.data  # we only take the first two features.\n",
    "y = boston.target\n",
    "\n",
    "# split into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cool thing about the built in sklearn datasets is that they have all these incredible descriptions built in as well.  Perfect for experiementing around with new packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print boston.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Algorithm\n",
    "\n",
    "The below K-NN regression takes the following arguments:\n",
    "\n",
    "- X_train: Features to build model on\n",
    "- y_train: Labels for training model\n",
    "- X_test: Features to predict on\n",
    "\n",
    "The model outputs the following\n",
    "\n",
    "- y_test: labels for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def distance(X, X_train):\n",
    "    return [np.sum((X - x)**2) for x in X_train]\n",
    "    \n",
    "def my_knn_regression(X_train, X_test, y_train, n_neighbors):\n",
    "    #find the closest n_neighbors in X_train to each point in X_test \n",
    "    #assign each point in X_test a label which is the most common label \n",
    "    #of its nearest n_neighbors\n",
    "    #return array y_test which is the array of above labels on X_test\n",
    "    y_test = []\n",
    "    for x in X_test:\n",
    "        #find the index of the cloest n_neighbors points to x in X_train\n",
    "        knn = np.argsort(distance(x, X_train))[:n_neighbors]\n",
    "        knn_value = np.mean(y_train[knn])\n",
    "        y_test.append(knn_value)\n",
    "    return np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test her out with 5 nearest neighbors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = my_knn_regression(X_train, X_test, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To judge the model performance, I'll be using a measure thats common in my line of work called MAPE.  Its the Mean Absolute Percent Error of our predictions with their actual values.  \n",
    "\n",
    "I would normally use the ```metrics``` package for measuring performance, but this is a manually implementation of the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error is:  0.214663492394\n"
     ]
    }
   ],
   "source": [
    "percent_error = []\n",
    "for i in range(len(y_hat)):\n",
    "    PE = (y_hat[i]-y_test[i])/y_test[i]\n",
    "    percent_error.append(PE)\n",
    "\n",
    "print \"average error is: \", np.mean(np.abs(percent_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! I think...\n",
    "\n",
    "Before I compare K-NN regression against other people machine learning algorithms, I'll first run a **hyper-parameter search** to find the number of *k* nearest neighbors that reduces our PE the most. **Hyper-parameters** are options we pass to machine learning algorithms to configure how they run.  In a tree-based algorithm, a hyperparameter might be maximum tree depth.  For a penalized linear regression, it might be the penalty assigned to additional variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will test our k-nn regression with a number of neighbors between 1 and 20 to find the one which minimizes our loss the most. \n",
    "\n",
    "If I were doing this in a production environment, I'd further split up my training dataset so that I'm finding the optimal set of neighbors on yet a different dataset than the one I'm building my model off of.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meta_knn_regression(X_train, X_test, y_train, n_max = 20):\n",
    "    best_PE = 100000\n",
    "    for i in range(n_max):\n",
    "        y_hat = my_knn_regression(X_train, X_test, y_train, i)\n",
    "        percent_error = []\n",
    "        for j in range(len(y_hat)):\n",
    "            PE = (y_hat[j]-y_test[j])/y_test[j]\n",
    "            percent_error.append(PE)\n",
    "        temp_PE = np.mean(np.abs(percent_error))\n",
    "        if temp_PE < best_PE:\n",
    "            best_PE = temp_PE\n",
    "            best_n = i\n",
    "            best_y_hat = y_hat\n",
    "    return best_y_hat, best_PE, best_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN produced an optimal mean error of 0.2050085244 using 8 nearest neighbors \n"
     ]
    }
   ],
   "source": [
    "y_hat, PE, n_neighbors = meta_knn_regression(X_train, X_test, y_train, n_max = 20)\n",
    "\n",
    "print \"KNN produced an optimal mean error of %s using %s nearest neighbors \" % (PE, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing KNN Regression against other machine learning algorithms.\n",
    "\n",
    "Now, using our KNN with optimized *k* hyperparameter, we'll compare our model against some other popular machine learning algorithms.\n",
    "\n",
    "This is the first time I'm bringing these algorithms into the picture, and my next posts will go over these models in greater depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import linear regression module from scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create an instance of a linear regressor from scikit learn\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# fit our chosen regressor to the dataset\n",
    "regressor.fit(X_train, y_train)  \n",
    "\n",
    "y_hat = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error is:  0.183501475863\n"
     ]
    }
   ],
   "source": [
    "percent_error = []\n",
    "for i in range(len(y_hat)):\n",
    "    PE = (y_hat[i]-y_test[i])/y_test[i]\n",
    "    percent_error.append(PE)\n",
    "\n",
    "print \"average error is: \", np.mean(np.abs(percent_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# create an instance of a elasticnet regressor from scikit learn\n",
    "regressor = ElasticNet(alpha=1)\n",
    "\n",
    "# fit our chosen regressor to the dataset\n",
    "regressor.fit(X_train, y_train)  \n",
    "\n",
    "y_hat = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error is:  0.194042726016\n"
     ]
    }
   ],
   "source": [
    "percent_error = []\n",
    "for i in range(len(y_hat)):\n",
    "    PE = (y_hat[i]-y_test[i])/y_test[i]\n",
    "    percent_error.append(PE)\n",
    "\n",
    "print \"average error is: \", np.mean(np.abs(percent_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# create an instance of the Random Forest Regressor from scikit learn\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "# fit our chosen regressor to the dataset\n",
    "regressor.fit(X_train, y_train)  \n",
    "\n",
    "y_hat = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error is:  0.134505708624\n"
     ]
    }
   ],
   "source": [
    "percent_error = []\n",
    "for i in range(len(y_hat)):\n",
    "    PE = (y_hat[i]-y_test[i])/y_test[i]\n",
    "    percent_error.append(PE)\n",
    "\n",
    "print \"average error is: \", np.mean(np.abs(percent_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# create an instance of the Random Forest Regressor from scikit learn\n",
    "regressor = GradientBoostingRegressor(loss='lad')\n",
    "\n",
    "# fit our chosen regressor to the dataset\n",
    "regressor.fit(X_train, y_train)  \n",
    "\n",
    "y_hat = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error is:  0.133206918853\n"
     ]
    }
   ],
   "source": [
    "percent_error = []\n",
    "for i in range(len(y_hat)):\n",
    "    PE = (y_hat[i]-y_test[i])/y_test[i]\n",
    "    percent_error.append(PE)\n",
    "\n",
    "print \"average error is: \", np.mean(np.abs(percent_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hmm - seems like our KNN algorithm didn't fare so hot compared to some other models. I've done a few Kaggle competititions where K-NN features strongly in my final ensemble of models, the poor performance here is a little surprising to me. My guess is that 8, while the optimal # of neighbors in our range of 20 tested, is actually pretty low.  I don't think I've done a competition where I have less than 100 neighbors in my final model, but then again this is a pretty small dataset to most of what is offered on Kaggle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
